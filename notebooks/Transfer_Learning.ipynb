{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "colab": {
      "name": "Benchmarks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z22BE9uhvoxO"
      },
      "source": [
        "# SciKeras Transfer Learning & Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hapoJed-voxP"
      },
      "source": [
        "Transfer learning is popular deep learning approach that involves re-purposing a model trained on one dataset onto another dataset. This notebook shows how to implement this in SciKeras. We will be following the [Keras tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning) on the topic, which goes much more in depth and breadth than we will here. You are highly encouraged to check out that tutorial if you want to learn about fine tuning and transfer learning in the general sense.\n",
        "\n",
        "\n",
        "\n",
        "<table align=\"left\"><td>\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/adriangb/scikeras/blob/master/notebooks/Basic_Usage.ipyn\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
        "</td><td>\n",
        "<a target=\"_blank\" href=\"https://github.com/adriangb/scikeras/blob/master/notebooks/Basic_Usage.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT-ibpi7voxQ"
      },
      "source": [
        "### Table of contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekJWKPFMvoxR"
      },
      "source": [
        "* [Data](#Data)\n",
        "* [Load Pre-Trained Model](#Model)\n",
        "* [Fine Tuning](#Keras-benchmark)\n",
        "* [SciKeras benchmark](#SciKeras-benchmark)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6avb3GBQDQyG"
      },
      "source": [
        "Install SciKeras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCcyTjVkvoxR"
      },
      "source": [
        "!python -m pip install git+https://github.com/adriangb/scikeras.git@master"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZveNcetDQyL"
      },
      "source": [
        "Silence TensorFlow warnings to keep output succint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekNmO_GPDQyL"
      },
      "source": [
        "import warnings\n",
        "from tensorflow import get_logger\n",
        "get_logger().setLevel('ERROR')\n",
        "warnings.filterwarnings(\"ignore\", message=\"Setting the random state for TF\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf4j-x4DvoxV"
      },
      "source": [
        "import numpy as np\n",
        "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
        "from tensorflow import keras"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCuOBH8AvoxX"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3fAUKBUvoxY"
      },
      "source": [
        "We load the dataset from the Keras tutorial. The dataset consists of images of cats and dogs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM74xeoe-1S-",
        "outputId": "23946eec-c32f-4db6-8bda-e12bda6492ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "IMG_SIZE = (160, 160)\n",
        "\n",
        "train_dataset = image_dataset_from_directory(train_dir,\n",
        "                                             shuffle=True,\n",
        "                                             image_size=IMG_SIZE)\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(validation_dir,\n",
        "                                                  shuffle=True,\n",
        "                                                  image_size=IMG_SIZE)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\nFound 1000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "Scikit-Learn (and by extension SciKeras) does not support `tf.DataSet`s. Altough this may change in the future, for now you need to convert your data to numpy arrays to use SciKeras. This has a performance impact and limits the size of the datasets to what can fit in-memory. If you encounter issues with this approach, you may need to use Keras directly."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "for batch in train_dataset.as_numpy_iterator():\n",
        "    X_train.append(batch[0])\n",
        "    y_train.append(batch[1])\n",
        "X_train = np.concatenate(X_train)\n",
        "y_train = np.concatenate(y_train)"
      ]
    },
    {
      "source": [
        "In this tutorial, we will not be using the validation set outside of Keras. Thus we can leave it as a `tf.DataSet` and pass it to `tf.keras.Model.fit` via the `fit__validation_data` routed param. Keras will then use this to compute validation metrics for each epoch."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuR10hymK0dh"
      },
      "source": [
        "## Define Keras Model"
      ]
    },
    {
      "source": [
        "We load a pre-trained MobileNet v2. We specify that we want the weights from the ImageNet dataset by passing `weights='imagenet'`"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBFFXT-__7KU"
      },
      "source": [
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqBl5xLDP43O"
      },
      "source": [
        "### Set up model for fine tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fHbt_mUVBhE"
      },
      "source": [
        "To fine tune the model, we first must pick some layers to train and some to freeze. Generally, we will want to train the upper layers of the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQhtIWsMP4Ii",
        "outputId": "1581384e-7012-4816-d4cf-a4190a30e50f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable =  False"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layers in the base model:  155\n"
          ]
        }
      ]
    },
    {
      "source": [
        "We now add input preprocessing and an output layer to `base_model` as well as a classifier head."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
        "x = preprocess_input(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEQyABtsVD2f"
      },
      "source": [
        "### Wrap the model with KerasClassifier"
      ]
    },
    {
      "source": [
        "In addition to freezing some layers, for fine tuning you will usually want to set a relatively low learning rate. This avoids overfitting to the new dataset and loss of generality, which would defeat the purpose of transfer learning."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-cjYYcJVhKt"
      },
      "source": [
        "clf = KerasClassifier(\n",
        "    model=model,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer__learning_rate=1e-5,\n",
        "    metrics=['accuracy'],\n",
        ")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 31s 489ms/step - loss: 0.1767 - accuracy: 0.9375 - val_loss: 0.0644 - val_accuracy: 0.9820\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 31s 492ms/step - loss: 0.0562 - accuracy: 0.9805 - val_loss: 0.0665 - val_accuracy: 0.9780\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 33s 516ms/step - loss: 0.0268 - accuracy: 0.9905 - val_loss: 0.0474 - val_accuracy: 0.9830\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 31s 498ms/step - loss: 0.0156 - accuracy: 0.9955 - val_loss: 0.0506 - val_accuracy: 0.9850\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 31s 493ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0888 - val_accuracy: 0.9700\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 32s 500ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.0538 - val_accuracy: 0.9840\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 30s 478ms/step - loss: 0.0059 - accuracy: 0.9975 - val_loss: 0.0566 - val_accuracy: 0.9820\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 29s 455ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9860\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 33s 522ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0625 - val_accuracy: 0.9830\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 31s 493ms/step - loss: 8.1556e-04 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9840\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KerasClassifier(\n",
              "\tmodel=<tensorflow.python.keras.engine.functional.Functional object at 0x150b023a0>\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=None\n",
              "\toptimizer=rmsprop\n",
              "\tloss=binary_crossentropy\n",
              "\tmetrics=['accuracy']\n",
              "\tbatch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=None\n",
              "\tvalidation_split=0.0\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=10\n",
              "\toptimizer__learning_rate=1e-05\n",
              "\tclass_weight=None\n",
              "\tfit__validation_data=<BatchDataset shapes: ((None, 160, 160, 3), (None,)), types: (tf.float32, tf.int32)>\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "clf.set_params(epochs=5)\n",
        "clf.set_params(fit__validation_data=validation_dataset)\n",
        "clf.fit(X_train, y_train)"
      ]
    }
  ]
}